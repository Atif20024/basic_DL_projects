{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task:**\n",
        "\n",
        "Create a DL training pipeline to train a LSTM/GRU (any one) and one Transformers\n",
        "network to identify Sentiments in a sentence. You are free to choose any open\n",
        "source dataset (like IMDB reviews or Amazon product ratings or any other). Report\n",
        "your accuracy. Create an inference pipeline which can accept a user text and provide\n",
        "score to each sentiment on it.**bold text**"
      ],
      "metadata": {
        "id": "ylpZOGSiSmCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2**. Transformer model finetuning approach"
      ],
      "metadata": {
        "id": "jpVGj86US0h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# module installation\n",
        "!pip install 'portalocker>=2.8.2' # for data_iter_downloading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y13KhUkjVJ3T",
        "outputId": "f6153cc2-9984-4836-eba4-855418883b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.8.2\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "402jxV2nSkA9",
        "outputId": "06522758-9a7a-451b-f9f4-9858cc703f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import IMDB\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchtext.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# device = torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3GRnF5d2nNB",
        "outputId": "414b8602-e275-40ed-e58e-5a64eac61691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_iter, test_data_iter = IMDB(split=('train', 'test'))"
      ],
      "metadata": {
        "id": "QTwwSTxuTz_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def get_dataframe(iterator=train_data_iter):\n",
        "  labels, reviews = [], []\n",
        "  for label, line in iterator:\n",
        "      labels.append(label)\n",
        "      reviews.append(line)\n",
        "  df = pd.DataFrame({'sentiment': labels, 'review': reviews})\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "PvK4WMFCaP2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = get_dataframe(train_data_iter)\n",
        "print(df_train.shape)\n",
        "df_test = get_dataframe(test_data_iter)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2CblGRLaP0b",
        "outputId": "4cefc84e-deb2-4a5b-ec9f-2c26c6b577a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 2)\n",
            "(25000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train['sentiment'].value_counts())\n",
        "print(df_test['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2GRC_gtaPyp",
        "outputId": "deaa14d8-dd32-4085-91b3-83a6ba46829b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "1    12500\n",
            "2    12500\n",
            "Name: count, dtype: int64\n",
            "sentiment\n",
            "1    12500\n",
            "2    12500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "HDZ05cqKSYJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "  # removing html tags that contains at max 10 character, incase someone wrote review in the brackets.\n",
        "  text = re.sub(r\"<[^>]{1,10}>\", \" \", text)\n",
        "\n",
        "  #removing all not alphabet charaters\n",
        "  text = re.sub(r\"[^A-Za-z .,']\", \" \", text)\n",
        "\n",
        "  # removing mulitple spaces\n",
        "  text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "  return text.strip(\" \").strip(\".\").lower()"
      ],
      "metadata": {
        "id": "JBunO5cNaPtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['review'] = df_train['review'].apply(clean_text)\n",
        "df_test['review'] = df_test['review'].apply(clean_text)\n",
        "\n",
        "df_train['sentiment'] = df_train['sentiment'] - 1\n",
        "df_test['sentiment'] = df_test['sentiment'] -1"
      ],
      "metadata": {
        "id": "WUtFn2oZGtCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_iter = [(row['sentiment'], row['review']) for _, row in df_train.iterrows()]\n",
        "test_data_iter = [(row['sentiment'], row['review']) for _, row in df_test.iterrows()]\n"
      ],
      "metadata": {
        "id": "Reaah70SjjpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building vocabolary\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "VOCAB_SIZE=20000\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "counter = Counter()\n",
        "for _, text in train_data_iter:\n",
        "    tokens = tokenizer(text)\n",
        "    counter.update(tokens)\n",
        "\n",
        "most_common = counter.most_common(VOCAB_SIZE)\n",
        "most_common = {f'{key[0]}': key[1] for key in most_common}\n",
        "\n",
        "vocab = vocab(Counter(most_common), specials=[\"<unk>\", \"<pad>\"])\n"
      ],
      "metadata": {
        "id": "-09O6HB0g1Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class BuildingReviewsDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, vocab, max_length):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['review']\n",
        "        label = self.data.iloc[idx]['sentiment']\n",
        "        tokens = self.tokenizer(text)[:self.max_length]\n",
        "        padded_tokens = tokens + ['<pad>'] * (self.max_length - len(tokens))\n",
        "        tokenized_text = torch.tensor([self.vocab[token] if token in self.vocab else self.vocab['<unk>'] for token in padded_tokens])\n",
        "        return tokenized_text, label"
      ],
      "metadata": {
        "id": "ejPwysZoF5CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "max_length = 250\n",
        "train_dataloader = DataLoader(BuildingReviewsDataset(df_train, tokenizer, vocab, max_length),\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(BuildingReviewsDataset(df_test, tokenizer, vocab, max_length),\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=False)\n"
      ],
      "metadata": {
        "id": "2ewm39f-F6Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentModelvTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=2, num_encoder_layers=3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model, nhead),\n",
        "            num_layers=num_encoder_layers)\n",
        "        self.fc = nn.Linear(d_model, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6wP-5VC5aPri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_trainable_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model = SentimentModelvTransformer(len(vocab))\n",
        "\n",
        "num_trainable_params = count_trainable_parameters(model)\n",
        "print(f\"Number of trainable parameters: {num_trainable_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fobgDr1WsJ02",
        "outputId": "f535c37e-6779-47b1-8374-a055d3f6231d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 4339586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TransformerModel = SentimentModelvTransformer(\n",
        "    len(vocab)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "RCuK9fNqaPpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(TransformerModel.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "WrEftipNR_Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "epochs_list = []\n",
        "training_loss_list = []\n",
        "test_loss_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_train_loss = 0\n",
        "    train_acc = 0\n",
        "    total_test_loss = 0\n",
        "    test_acc = 0\n",
        "    TransformerModel.train()\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        inputs, labels = batch\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_acc += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    train_accuracy = train_acc / len(df_train)\n",
        "\n",
        "    TransformerModel.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch in test_dataloader:\n",
        "            inputs, labels = batch\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_acc += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    test_accuracy = test_acc / len(df_test)\n",
        "\n",
        "    epochs_list.append(epoch)\n",
        "    training_loss_list.append(avg_train_loss)\n",
        "    test_loss_list.append(avg_test_loss)\n",
        "    test_acc_list.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Avg Training Loss: {avg_train_loss:.3f}, Training Accuracy: {train_accuracy: .2f}, Avg Test Loss: {avg_test_loss:.3f}, Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MzdegF1LaPkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(12, 5))\n",
        "\n",
        "# # Plotting Loss\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(epochs_list, [tensor.detach().cpu().numpy() for tensor in training_loss_list] , label='Training Loss', marker='o')\n",
        "# plt.plot(epochs_list, [tensor.detach().cpu().numpy() for tensor in test_loss_list], label='Test Loss', marker='x')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Training and Test Loss')\n",
        "# plt.legend()\n",
        "\n",
        "# # Plotting Accuracy\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(epochs_list, test_acc_list, label='Test Accuracy', marker='o', color='green')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Test Accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "uRHjskTP9xEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference pipeline\n",
        "\n",
        "def preprocess_text(input_text, vocab, tokenizer, max_length):\n",
        "    tokens = tokenizer(text)[:max_length]\n",
        "    padded_tokens = tokens + ['<pad>'] * (max_length - len(tokens))\n",
        "    tokenized_text = torch.tensor([vocab[token] if token in vocab else vocab['<unk>'] for token in padded_tokens])\n",
        "    return tokenized_text\n",
        "\n",
        "def predict_sentiment(text, model, vocab, tokenizer, max_length):\n",
        "    TransformerModel.eval()\n",
        "    with torch.inference_mode():\n",
        "        tokenized_text = preprocess_text(text, vocab, tokenizer, max_length)\n",
        "        input_tensor = tokenized_text.unsqueeze(0).to(device)\n",
        "        prediction = model(input_tensor)\n",
        "        return prediction\n",
        "\n",
        "input_text = \"worst movie ever\"\n",
        "sentiment = predict_sentiment(input_text, TransformerModel, vocab, tokenizer, max_length)\n",
        "\n",
        "sentiment_in_words = \"positive\" if sentiment.argmax() == 1 else \"negative\"\n",
        "print(\"Sentiment:\", sentiment_in_words)"
      ],
      "metadata": {
        "id": "ffZvhPWZfwaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5fb337e-bb16-4a5e-c6ea-a41ea668a1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCL3L4Q_1c7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}